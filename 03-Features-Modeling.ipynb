{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "### Main flavors of data and feature engineering\n",
    "* Tabular: Dataframe model\n",
    "    * \"Typical\" business data tables\n",
    "* Batch/Tensor/Vector: Array model\n",
    "    * Numeric data, timeseries, scientific data, audio, images, video, geodata, etc.\n",
    "* Natural language\n",
    "    * Batches of strings\n",
    "    * Transformed into array data through NLP-specific techniques\n",
    "    \n",
    "<img src='images/flow-transform.png' width=800>\n",
    "\n",
    "### \"Must-haves\" for feature engineering on large data\n",
    "\n",
    "* Some data representation for the large dataset\n",
    "    * Likely distributed, out-of-core, lazy, streaming, etc.\n",
    "* Mechanism to load data from standard formats and locations into the representation\n",
    "    * E.g., loading HDF5 in S3 or Parquet in HDFS\n",
    "* APIs to apply feature engineering transformations\n",
    "    * Mathematical operations\n",
    "    * String, date, etc.\n",
    "    * Custom (\"user-defined\")\n",
    "* Integration to a modeling framework and/or ability to write to standard formats\n",
    "\n",
    "### \"Nice-to-haves\"\n",
    "\n",
    "* Intuitive data representation: similar to \"small data\" tooling\n",
    "* APIs that resemble those of the most common industry-standard libraries\n",
    "* Both modeling integration *and* ability to write out transformed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIXME: image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rise of Python\n",
    "\n",
    "Python has become the *lingua franca* or dominant cross-cutting language for data science.\n",
    "\n",
    ">\n",
    "> __Note__ this is not to imply Python is the best or only language, or that other languages might not be intrinsically better or even, in the future, more successful. \n",
    ">\n",
    "> There are wonderful things to be said for languages from Rust to R to Julia to many others, but for baseline data science capability and versatility in commercial enterprises today, it's Python\n",
    ">\n",
    "\n",
    "So we can turn to Python and look at the dominant libraries and tools within that ecosystem\n",
    "* Tabular data: Pandas\n",
    "* Array data: NumPy and derivatives like CuPy, JAX.numpy, etc.\n",
    "* Basic modeling: scikit-learn, XGBoost, etc.\n",
    "* Deep learning: PyTorch, Tensorflow\n",
    "* NLP: SpaCy, NLTK, Huggingface, etc.\n",
    "\n",
    "As we get into further parts of the workflow, like hyperparameter tuning or reinforcement learning there are more choices. \n",
    "\n",
    "For time reasons, we're going to stick to this core workflow of extraction through modeling and tuning, and not continue on into MLOps and deploment architectures, or meta-modeling platforms for experimentation, feature and provenance tracking, etc. That would be a bit too much to take on!\n",
    "\n",
    "__Bottom line__: We want a data representation and APIs that are fairly close to the Pandas / NumPy / scikit-learn (SciPy) workflow. And we want elegant bridges into things like PyTorch, XGBoost, NLP tools, and tuning tools.\n",
    "\n",
    "## Dask: SciPy at Scale\n",
    "\n",
    "Luckily, Dask is well placed to solve this problem. \n",
    "\n",
    "While enterprises were still wrestling with JVM-based tools over the past 5 years, scientists, researchers, and others in the PyData and SciPy communities were building Dask, a pure-Python distributed compute platform that integrates deeply with all of the standard SciPy tools.\n",
    "\n",
    "__What does this mean?__\n",
    "\n",
    "We can take many of our local workflows to large-scale data via Dask with fairly minimal effort -- because under the hood, Dask is designed to use those \"small data\" structures in federation to create arbitrarily large ones.\n",
    "\n",
    "FIXME: Dask DF and Array images\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an added bonus, due to the Dask architecture, it can leverage GPU-enabled versions of the underlying libraries.\n",
    "* GPU + NumPy => CuPy\n",
    "* GPU + Pandas => cuDF (RAPIDS CUDA dataframe)\n",
    "* GPU + scikit-learn => cuML (RAPIDS CUDA algorithms)\n",
    "etc.\n",
    "\n",
    "### Using Dask for Feature Transformation\n",
    "\n",
    "* We need to be able to load data in a standard format\n",
    "* Manipulate it using dataframe or array APIs\n",
    "* Write it and/or pass it efficiently to a modeling framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import dataframe as ddf\n",
    "from dask import array as da\n",
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(n_workers=2, threads_per_worker=1, memory_limit='1GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:52321</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>2</li>\n",
       "  <li><b>Cores: </b>2</li>\n",
       "  <li><b>Memory: </b>2.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:52321' processes=2 threads=2, memory=2.00 GB>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
